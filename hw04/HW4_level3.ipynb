{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "dz-y9SyPihZR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 匯入必要套件"
      ],
      "metadata": {
        "id": "ZUPqei5GYSf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For drawing\n",
        "import matplotlib.pyplot as plt\n",
        "# For data processing\n",
        "import numpy as np\n",
        "import os\n",
        "# For buildind model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNet"
      ],
      "metadata": {
        "id": "iUMJrUroE7ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 資料處理"
      ],
      "metadata": {
        "id": "2lK-COdKYaHR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDaVE6eSDBjw"
      },
      "outputs": [],
      "source": [
        "# 從指定的URL下載並提取檔案\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "# 返回下載的檔案路徑，並將檔案提取到預設的位置\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "# 將最終的資料夾路徑存儲\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 指定訓練集和驗證集的資料夾路徑\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "# 設定 batch_size 和 img_size\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224) # MobileNet v1 的輸入大小\n",
        "\n",
        "#建立訓練集\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir, #訓練集路徑\n",
        "                                                            shuffle=True, #隨機選取\n",
        "                                                            batch_size=BATCH_SIZE,\n",
        "                                                            image_size=IMG_SIZE)\n",
        "\n",
        "#建立驗證集\n",
        "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir, #驗證集路徑\n",
        "                                                                 shuffle=True,\n",
        "                                                                 batch_size=BATCH_SIZE,\n",
        "                                                                 image_size=IMG_SIZE)"
      ],
      "metadata": {
        "id": "BX23ORFoE3rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#把部分驗證集資料，當作測試集\n",
        "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "test_dataset = validation_dataset.take(val_batches // 5) #拿1/5(6筆)的資料當作測試集\n",
        "validation_dataset = validation_dataset.skip(val_batches // 5)  #拿剩下4/5(26筆)的資料當作驗證集\n",
        "\n",
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
      ],
      "metadata": {
        "id": "uZKrOFUxE89T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 調整執行效能記憶體優化"
      ],
      "metadata": {
        "id": "WpywXh65YjqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE) #記憶體優化\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE) #記憶體優化\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE) #記憶體優化"
      ],
      "metadata": {
        "id": "Z3HV6l7cRzxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 影像縮放"
      ],
      "metadata": {
        "id": "WLxSjClnY7gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立資料擴增函式\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal'), # 水平翻轉\n",
        "  tf.keras.layers.RandomRotation(0.2), # 旋轉\n",
        "])"
      ],
      "metadata": {
        "id": "VmZjNhzpY4Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 建立模型"
      ],
      "metadata": {
        "id": "_ECL4WjzYexz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立模型 (不包含全連接層)\n",
        "# weights='imagenet' 表示使用在 ImageNet 上預訓練的權重初始化模型\n",
        "base_model = MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "# 取得資料集中的下一個批次\n",
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)"
      ],
      "metadata": {
        "id": "uwhgxQ6oaVTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 不更新權重"
      ],
      "metadata": {
        "id": "G77ugMGWYhXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 模型的權重在訓練過程中將不會被更新\n",
        "base_model.trainable = False\n",
        "# 印出模型概述\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "A67XMSKGa6S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立一個全域平均池化層，將輸入特徵張量的空間維度進行平均壓縮，保留通道維度\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "# 獲得每個通道的平均值\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)"
      ],
      "metadata": {
        "id": "ruPRYUQ1bEsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 分類器是二值分類(用BinaryCrossentropy)，所以只有一個輸出\n",
        "# 將全域平均池化後的特徵向量映射到單一預測值\n",
        "prediction_layer = tf.keras.layers.Dense(1)\n",
        "# 將全域平均池化後的特徵向量作為輸入，經過全連接層進行預測操作\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ],
      "metadata": {
        "id": "W4KwItqxbQBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(224, 224, 3)) #將輸入影像尺寸resize到160x160x3\n",
        "x = data_augmentation(inputs) #輸入影像資料擴增\n",
        "x = base_model(x, training=False) #靜止更改 base_model\n",
        "x = global_average_layer(x) #5x5 Average Pooling 空間平均\n",
        "x = tf.keras.layers.Dropout(0.2)(x) # 20% 節點隨機設成0輸出\n",
        "outputs = prediction_layer(x) #換算成機率值\n",
        "model = tf.keras.Model(inputs, outputs) #定義新模型的名稱"
      ],
      "metadata": {
        "id": "elYMsXBjbUfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#設定訓練超參數\n",
        "base_learning_rate = 0.0001 #學習率\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), #使用二值交叉熵\n",
        "              metrics=['accuracy']) #以準確率為指標\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "TCnDKPwCbVAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(model.trainable_variables)) # 0:weights, 1:bias\n",
        "weights_=np.array(model.trainable_variables[0])\n",
        "print(len(weights_)) # 1280 weights\n",
        "bias_=np.array(model.trainable_variables[1])\n",
        "print(len(bias_)) # 1 bias"
      ],
      "metadata": {
        "id": "1gVmaM_SbZc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_epochs = 10 # 設定迭代次數\n",
        "\n",
        "loss0, accuracy0 = model.evaluate(validation_dataset) # 評估模型的損失和準確率\n",
        "\n",
        "print(\"initial loss: {:.2f}\".format(loss0))\n",
        "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
      ],
      "metadata": {
        "id": "ksYQFCZjbcQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #新Model的訓練\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_dataset,\n",
        "                    verbose=2) #只檢視結果"
      ],
      "metadata": {
        "id": "17AvqNREbhCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#繪製訓練與驗證集的準確度與loss歷史曲線\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FuBGuaaTblxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 允許更新權重 (做Fine-tune處理)"
      ],
      "metadata": {
        "id": "2Oxwqh2UYs2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True # 允許更新權重\n",
        "\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards 從100層調起\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False #前100層不準調整"
      ],
      "metadata": {
        "id": "5myFoacgbytw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ZRecJRnxb10a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.trainable_variables)"
      ],
      "metadata": {
        "id": "ly0sSNSyb7YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_epochs = 10\n",
        "total_epochs =  initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(train_dataset,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=validation_dataset,\n",
        "                         verbose=2) #只顯示結果"
      ],
      "metadata": {
        "id": "Q5xlkgDcb9os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 增添微調訓練的歷史資料(準確度與loss)\n",
        "acc += history_fine.history['accuracy']\n",
        "val_acc += history_fine.history['val_accuracy']\n",
        "\n",
        "loss += history_fine.history['loss']\n",
        "val_loss += history_fine.history['val_loss']"
      ],
      "metadata": {
        "id": "J3OOB1aCcDWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 綠線右方是微調訓練的成果\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.ylim([0, 1.0])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.ylim([0, 1.0])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2uD8BndccFAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print('Test accuracy :', accuracy)"
      ],
      "metadata": {
        "id": "46kxOseqcFj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 只有 train_data 和 test_data 的模型訓練"
      ],
      "metadata": {
        "id": "dz-y9SyPihZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# 載入MobileNet模型\n",
        "base_model = MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# 凍結模型的權重\n",
        "base_model.trainable = False\n",
        "\n",
        "# 建立模型架構\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 編譯模型\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 訓練模型\n",
        "epochs = 10\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=validation_generator)\n",
        "\n",
        "# 評估模型\n",
        "test_loss, test_acc = model.evaluate(validation_generator)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "AMeRzCDJU27T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}