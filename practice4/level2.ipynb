{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "Bu6nW2cpbmiS",
        "NTSbdcbGfaMy",
        "YPMDx7lWhpK2",
        "5gDtGx0Jire4",
        "50mCPSL1RIk2",
        "yF3vF8xJRjkK",
        "Wb_QsVGBR92N",
        "Tv09wc-rSPgh",
        "DBYIEk46zt4v",
        "Adu_Z3cK6dA7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 資料準備"
      ],
      "metadata": {
        "id": "-49IsLTsxLic"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxpF8mgFv04F"
      },
      "outputs": [],
      "source": [
        "# 匯入必要套件\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 匯入資料集\n",
        "from keras.datasets import cifar10\n",
        "# 資料集切割成訓練與測試資料\n",
        "(x_img_train,y_label_train),(x_img_test,y_label_test)=cifar10.load_data()\n",
        "\n",
        "# 資料大小\n",
        "print(\"train data:\",'images:',x_img_train.shape,\n",
        "      \" labels:\",y_label_train.shape) \n",
        "print(\"test  data:\",'images:',x_img_test.shape ,\n",
        "      \" labels:\",y_label_test.shape) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 對資料做歸一化處理\n",
        "x_img_train_normalize = x_img_train.astype('float32') / 255.0\n",
        "x_img_test_normalize = x_img_test.astype('float32') / 255.0\n",
        "\n",
        "# 對資料樣本作類別標籤(OneHot Code)\n",
        "from keras.utils import np_utils\n",
        "y_label_train_OneHot = np_utils.to_categorical(y_label_train)\n",
        "y_label_test_OneHot = np_utils.to_categorical(y_label_test)\n",
        "\n",
        "# 類別標籤大小 (測試資料筆數:類別總筆數)\n",
        "y_label_test_OneHot.shape"
      ],
      "metadata": {
        "id": "sw2YuFBZxWs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型方法"
      ],
      "metadata": {
        "id": "D96dlx98sSeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 匯入搭建神經網路模型套件\n",
        "from keras import models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ],
      "metadata": {
        "id": "lIzEiROow3Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義建立模型方法 (預設參數: 神經網路層數=2, 步數=1, 激活函數='relu', 隨機丟參率=0.25, 優化器='adam')\n",
        "def create_model(layers=2, filters=32, stride=1, activation='relu', drop_rate=0.25, optimizer='adam'):\n",
        "  # 建立模型\n",
        "  model = Sequential()\n",
        "\n",
        "  for i in range(layers):\n",
        "    # 添加卷積層和池化層(i+1)\n",
        "    model.add(Conv2D(filters=filters, \n",
        "                    kernel_size=(3,3), \n",
        "                    strides=(stride, stride),\n",
        "                    padding='same', \n",
        "                    activation=activation, \n",
        "                    input_shape=(32,32,3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(drop_rate))\n",
        "\n",
        "  # 添加平坦層\n",
        "  model.add(Flatten())\n",
        "  # 添加全連接層\n",
        "  model.add(Dense(1024, activation))\n",
        "  model.add(Dropout(drop_rate))\n",
        "  # 添加輸出層 (分成10類，激活函數='softmax')\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  # 編譯模型\n",
        "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "aFMfgqySxDUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準確率/損失率"
      ],
      "metadata": {
        "id": "unfu8XsDaVAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# # 顯示準確率曲線\n",
        "# def show_acc_history(history, train_acc,test_acc):\n",
        "#     plt.figure(figsize=(8, 6))\n",
        "#     plt.plot(history.history[train_acc])\n",
        "#     plt.plot(history.history[test_acc])\n",
        "#     plt.title('Train History')\n",
        "#     plt.ylabel('Accuracy')\n",
        "#     plt.xlabel('Epoch')\n",
        "#     plt.legend(['train', 'test'], loc='upper left')\n",
        "#     plt.show()\n",
        "\n",
        "# # 顯示損失率曲線\n",
        "# def show_loss_history(history, train_loss,test_loss):\n",
        "#     plt.figure(figsize=(8, 6))\n",
        "#     plt.plot(history.history[train_loss])\n",
        "#     plt.plot(history.history[test_loss])\n",
        "#     plt.title('Train History')\n",
        "#     plt.ylabel('Loss')\n",
        "#     plt.xlabel('Epoch')\n",
        "#     plt.legend(['train', 'test'], loc='upper left')\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "1JmcLYDiaUVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義繪製訓練準確率與損失率方法\n",
        "def show_history(history, train_acc, test_acc, train_loss, test_loss):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # 顯示準確率曲線\n",
        "    ax1.plot(history.history[train_acc])\n",
        "    ax1.plot(history.history[test_acc])\n",
        "    ax1.set_title('Accuracy')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "    # 顯示損失率曲線\n",
        "    ax2.plot(history.history[train_loss])\n",
        "    ax2.plot(history.history[test_loss])\n",
        "    ax2.set_title('Loss')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0a9o4W-ECkHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型訓練"
      ],
      "metadata": {
        "id": "yBel4vLSavsJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **原始參數**\n",
        "```\n",
        "layers=2, filters=32, stride=1, activation='relu', drop_rate=0.25, optimizer='adam'\n",
        "```\n",
        "```\n",
        "batch_size=32\n",
        "```"
      ],
      "metadata": {
        "id": "Q4Ez3Ai5bIe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立模型(原始參數)\n",
        "model = create_model()\n",
        "# 模型總表\n",
        "print(model.summary())\n",
        "\n",
        "# validation_data：使用固定的驗證資料集\n",
        "# validation_split：使用訓練資料的一部分作為驗證資料集\n",
        "history = model.fit(x_img_train_normalize, y_label_train_OneHot, validation_data=(x_img_test_normalize, y_label_test_OneHot), epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# 繪製準確率 / 損失率\n",
        "show_history(history,'accuracy','val_accuracy', 'loss', 'val_loss')"
      ],
      "metadata": {
        "id": "R_ieoA0cyWqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **調整濾鏡參數(filters)**\n",
        "```\n",
        "layers=2, filters=[32, 64, 128], stride=1, activation='relu', drop_rate=0.25, optimizer='adam'\n",
        "```\n",
        "\n",
        "``` filters = 32 ``` 時， 效果最佳"
      ],
      "metadata": {
        "id": "Bu6nW2cpbmiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # 建立模型 (filters=32, 64, 128)\n",
        "# ### filters = 32 效果最佳\n",
        "\n",
        "# filters = [32, 64, 128]\n",
        "\n",
        "# for i in range(len(filters)):\n",
        "#   model = create_model(filters=filters[i])\n",
        "#   result = model.fit(x_img_train_normalize, y_label_train_OneHot, validation_data=(x_img_test_normalize, y_label_test_OneHot), epochs=10, batch_size=32, verbose=1)\n",
        "#   show_acc_history(result,'accuracy','val_accuracy')\n",
        "#   show_loss_history(result, 'loss', 'val_loss')"
      ],
      "metadata": {
        "id": "1_tS0uAccfuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **調整激活函數(activation)**\n",
        "```\n",
        "layers=2, filters=32, stride=1, activation=['relu', 'softmax', 'tanh', 'sigmoid', 'LeakyReLU'], drop_rate=0.25, optimizer='adam'\n",
        "```\n",
        "\n",
        "``` activation = 'LeakyReLU' ``` 時，效果最佳"
      ],
      "metadata": {
        "id": "NTSbdcbGfaMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 更改激活函數 (activation='relu', 'softmax', 'tanh', 'sigmoid', 'LeakyReLU')\n",
        "# ### 'relu' 與 'LeakyReLU' 表現較佳  -> 'LeakyReLU' 稍好一些\n",
        "\n",
        "# activations = [tf.keras.activations.relu, \n",
        "#               #  tf.keras.activations.softmax, \n",
        "#               #  tf.keras.activations.tanh, \n",
        "#               #  tf.keras.activations.sigmoid, \n",
        "#                tf.keras.layers.LeakyReLU(alpha=0.01)]\n",
        "\n",
        "# for i in range(len(activations)):\n",
        "#   model = create_model(activation=activations[i])\n",
        "#   result = model.fit(x_img_train_normalize, y_label_train_OneHot, validation_data=(x_img_test_normalize, y_label_test_OneHot), epochs=10, batch_size=32, verbose=1)\n",
        "#   show_acc_history(result,'accuracy','val_accuracy')\n",
        "#   show_loss_history(result, 'loss', 'val_loss')"
      ],
      "metadata": {
        "id": "c_77XemVgyjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **調整優化器(optimizer)**\n",
        "```\n",
        "layers=2, filters=32, stride=1, activation='relu', drop_rate=0.25, optimizer=['adam', 'SGD', 'RMSProp', 'Adagrad', 'Adadelta']\n",
        "```\n",
        "\n",
        "``` optimizer = 'adam' ``` 時，效果最佳"
      ],
      "metadata": {
        "id": "YPMDx7lWhpK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 更改優化器 (optimizer='adam', 'SGD', 'RMSProp', 'Adagrad', 'Adadelta')\n",
        "# ### 'adam', 'RMSProp' 表現較佳  -> 'adam' 表現稍好\n",
        "\n",
        "# optimizers = [tf.keras.optimizers.Adam()]\n",
        "#               # tf.keras.optimizers.SGD(),\n",
        "#               # tf.keras.optimizers.RMSprop(),\n",
        "#               # tf.keras.optimizers.Adagrad(),\n",
        "#               # tf.keras.optimizers.Adadelta()\n",
        "\n",
        "# for i in range(len(optimizers)):\n",
        "#   model = create_model(optimizer=optimizers[i])\n",
        "#   result = model.fit(x_img_train_normalize, y_label_train_OneHot, validation_data=(x_img_test_normalize, y_label_test_OneHot), epochs=10, batch_size=32, verbose=1)\n",
        "#   show_acc_history(result,'accuracy','val_accuracy')\n",
        "#   show_loss_history(result, 'loss', 'val_loss')"
      ],
      "metadata": {
        "id": "qudSyLLciK79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **調整步幅(stride)**\n",
        "```\n",
        "layers=2, filters=32, stride=[1,2], activation='relu', drop_rate=0.25, optimizer='adam'\n",
        "```\n",
        "\n",
        "``` stride = 1 ``` 時，效果最佳"
      ],
      "metadata": {
        "id": "5gDtGx0Jire4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 更改步幅 (stride=1, 2)\n",
        "# ### stride = 1 效果較佳\n",
        "\n",
        "# # strides = [1, 2]\n",
        "\n",
        "\n",
        "# for i in range(len(strides)):\n",
        "#   model = create_model(stride=strides[i])\n",
        "#   result = model.fit(x_img_train_normalize, y_label_train_OneHot, validation_data=(x_img_test_normalize, y_label_test_OneHot), epochs=10, batch_size=32, verbose=1)\n",
        "#   show_acc_history(result,'accuracy','val_accuracy')\n",
        "#   show_loss_history(result, 'loss', 'val_loss')"
      ],
      "metadata": {
        "id": "cRp0cLryjE1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **調整卷積層數(layers)**\n",
        "```\n",
        "layers=range(2, 5), filters=32, stride=[1,2], activation='relu', drop_rate=0.25, optimizer='adam'\n",
        "```\n",
        "\n",
        "``` layers = 2 ``` 時，效果最佳"
      ],
      "metadata": {
        "id": "50mCPSL1RIk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 更改卷積層數 (layers=range(2, 5))\n",
        "### layers=2 時效果最佳\n",
        "\n",
        "# for i in range(2, 5):\n",
        "#   model = create_model(layers=i)\n",
        "#   result = model.fit(x_img_train_normalize, y_label_train_OneHot, validation_data=(x_img_test_normalize, y_label_test_OneHot), epochs=10, batch_size=32, verbose=1)\n",
        "#   show_acc_history(result,'accuracy','val_accuracy')\n",
        "#   show_loss_history(result, 'loss', 'val_loss')"
      ],
      "metadata": {
        "id": "ws4qs4czSLRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **調整Dropout參數**\n",
        "```\n",
        "layers=2, filters=32, stride=[1,2], activation='relu', drop_rate=range(0.2, 0.5, 0.05), optimizer='adam'\n",
        "```\n",
        "\n",
        "``` drop_rate = 0.3 ``` 時，效果最佳"
      ],
      "metadata": {
        "id": "yF3vF8xJRjkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 更改Dropout (drop_rate=range(0.2, 0.5, 0.05))\n",
        "### drop_rate = 0.3 > 0.25 > 0.2 效果佳對比\n",
        "\n",
        "drop_rate = np.arange(0.2, 0.5, 0.05)\n",
        "\n",
        "# for rate in drop_rate:\n",
        "#   model = create_model(drop_rate=rate)\n",
        "#   result = model.fit(x_img_train_normalize, y_label_train_OneHot, validation_data=(x_img_test_normalize, y_label_test_OneHot), epochs=10, batch_size=32, verbose=1)\n",
        "#   show_acc_history(result,'accuracy','val_accuracy')\n",
        "#   show_loss_history(result, 'loss', 'val_loss')"
      ],
      "metadata": {
        "id": "BO4qrL4RSM8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **調整批量(batch_size)**\n",
        "```\n",
        "layers=2, filters=32, stride=[1,2], activation='relu', drop_rate=0.25, optimizer='adam'\n",
        "```\n",
        "```\n",
        "batch_size = [16, 32, 64]\n",
        "```\n",
        "\n",
        "``` batch_size = 64``` 時，效果最佳"
      ],
      "metadata": {
        "id": "Wb_QsVGBR92N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H0fTxJEAyQfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 更改批量 (batch_size=[16, 32, 64])\n",
        "### batch_size = 64 > 32 > 16\n",
        "\n",
        "batch_size = [16, 32, 64]\n",
        "\n",
        "# for batch in batch_size:\n",
        "#   model = create_model()\n",
        "#   result = model.fit(x_img_train_normalize, y_label_train_OneHot, validation_data=(x_img_test_normalize, y_label_test_OneHot), epochs=10, batch_size=batch, verbose=1)\n",
        "#   show_acc_history(result,'accuracy','val_accuracy')\n",
        "#   show_loss_history(result, 'loss', 'val_loss')"
      ],
      "metadata": {
        "id": "hCcWZIfnHnPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **影像擴增**\n",
        "\n",
        "執行結果沒有比較好 --> 不予採用"
      ],
      "metadata": {
        "id": "Tv09wc-rSPgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 影像擴增\n",
        "\n",
        "# # 定義資料擴增方法\n",
        "# def data_augmentation(image, label):\n",
        "#     # 隨機水平翻轉\n",
        "#     image = tf.image.random_flip_left_right(image)\n",
        "    \n",
        "#     # 隨機旋轉\n",
        "#     image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "\n",
        "    \n",
        "#     # 隨機調整亮度\n",
        "#     image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    \n",
        "#     # 隨機調整對比度\n",
        "#     image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n",
        "    \n",
        "#     return image, label\n",
        "\n",
        "# # 建立訓練資料集\n",
        "# train_dataset = tf.data.Dataset.from_tensor_slices((x_img_train_normalize, y_label_train_OneHot))\n",
        "# train_dataset = train_dataset.shuffle(50000).map(data_augmentation).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# # 建立測試資料集\n",
        "# test_dataset = tf.data.Dataset.from_tensor_slices((x_img_test_normalize, y_label_test_OneHot))\n",
        "# test_dataset = test_dataset.batch(32).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "7oXiXxbQSVaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = create_model(drop_rate=0.3, activation=tf.keras.layers.LeakyReLU(alpha=0.01))\n",
        "# result = model.fit(train_dataset, epochs=10, validation_data=test_dataset, batch_size=32, verbose=1)\n",
        "\n",
        "# show_acc_history(result,'accuracy','val_accuracy')\n",
        "# show_loss_history(result, 'loss', 'val_loss')"
      ],
      "metadata": {
        "id": "-Qom78z1PTJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 評估模型\n",
        "# scores = model.evaluate(x_img_test_normalize, y_label_test_OneHot)\n",
        "# print('Test loss:', scores[0])\n",
        "# print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "id": "gmiLVCMK5os8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Filter調參：使用網格搜尋(Grid Search) --> 非常不現實的決定"
      ],
      "metadata": {
        "id": "DBYIEk46zt4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KerasClassifier 可以將模型當成scikit-learn中的估計器(estimator)來使用，以便進行機器學習中的交叉驗證和超參數調整\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "metadata": {
        "id": "dcVZgV36zlIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 將模型包裝成 KerasClassifier\n",
        "# model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "# # 定義要調整的 filter 參數範圍\n",
        "# param_grid = {'filters_1': [32, 64, 128], 'filters_2': [32, 64, 128]}\n",
        "# # 使用 GridSearchCV 進行自動調參\n",
        "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
        "# grid_result = grid.fit(x_img_train_normalize, y_label_train_OneHot)\n",
        "\n",
        "# # 輸出最佳參數組合和對應的準確度\n",
        "# print(\"Best Parameters: \", grid_result.best_params_)\n",
        "# print(\"Best Accuracy: \", grid_result.best_score_)"
      ],
      "metadata": {
        "id": "TTxUgm5qz_8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 貝葉斯優化：卷積層數(Layers)與濾鏡數量(Filters) --> 運算資源不足 = 不現實的決定"
      ],
      "metadata": {
        "id": "Adu_Z3cK6dA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "jhu6SBzm_Nmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import optuna\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# def optimize(trial):\n",
        "#   # 定義超參數搜索範圍\n",
        "#   n_layers = trial.suggest_int('n_layers', 2, 5)\n",
        "\n",
        "#   model = Sequential()\n",
        "#   # 添加卷積層\n",
        "#   for _ in range(n_layers):\n",
        "#       n_filters = trial.suggest_int('n_filters', 32, 128)\n",
        "#       model.add(Conv2D(n_filters, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "#       model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#       model.add(Dropout(rate=0.25))\n",
        "\n",
        "#   # 添加平坦層\n",
        "#   model.add(Flatten())\n",
        "#   # 添加全連接層\n",
        "#   model.add(Dense(1024, activation='relu'))\n",
        "#   model.add(Dropout(rate=0.25))\n",
        "#   # 添加輸出層\n",
        "#   model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#   # 編譯模型\n",
        "#   model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "#   # 訓練模型\n",
        "#   model.fit(x_img_train_normalize, y_label_train_OneHot, validation_data=(x_img_test_normalize, y_label_test_OneHot), epochs=10, batch_size=32, verbose=1)  \n",
        "#   # 計算驗證集上的準確度\n",
        "#   y_pred = model.predict(x_img_test_normalize)\n",
        "#   y_pred = np.argmax(y_pred, axis=1)\n",
        "#   accuracy = accuracy_score(np.argmax(y_label_test_OneHot, axis=1), y_pred)\n",
        "  \n",
        "#   return accuracy"
      ],
      "metadata": {
        "id": "4a9MQhDE6apz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 創建Optuna優化器並執行優化\n",
        "# study = optuna.create_study(direction='maximize')\n",
        "# study.optimize(optimize, n_trials=100)\n",
        "\n",
        "# # 取得最佳的超參數組合\n",
        "# best_params = study.best_params\n",
        "# best_accuracy = study.best_value\n",
        "\n",
        "# print('Best Parameters:', best_params)\n",
        "# print('Best Accuracy:', best_accuracy)"
      ],
      "metadata": {
        "id": "uuijSeoc_Uxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 設定參數範圍\n",
        "# param_grid = {'stride': [1, 2]}\n",
        "\n",
        "# # 建立Keras分類器\n",
        "# model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# # 使用GridSearchCV進行自動化調參\n",
        "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
        "# grid_result = grid.fit(x_img_train_normalize, y_label_train_OneHot)\n",
        "\n",
        "# # 印出最佳結果\n",
        "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "metadata": {
        "id": "pOsh93J9ciqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import optuna\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from keras.datasets import cifar10\n",
        "# from keras.utils import np_utils\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # 載入CIFAR-10資料集\n",
        "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# # 對資料做歸一化處理\n",
        "# x_train = x_train.astype('float32') / 255.0\n",
        "# x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# # 對資料樣本作類別標籤(OneHot Code)\n",
        "# num_classes = 10\n",
        "# y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "# y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# # 分割訓練集和驗證集\n",
        "# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# def create_model(trial):\n",
        "#     model = keras.Sequential()\n",
        "#     model.add(keras.layers.Conv2D(trial.suggest_int('filters_1', 16, 64), kernel_size=(3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "#     model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(trial.suggest_int('stride_1', 1, 2))))\n",
        "    \n",
        "#     for i in range(trial.suggest_int('num_layers', 1, 3)):\n",
        "#         model.add(keras.layers.Conv2D(trial.suggest_int(f'filters_{i+2}', 16, 64), kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "#         model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(trial.suggest_int(f'stride_{i+2}', 1, 2))))\n",
        "\n",
        "#     model.add(keras.layers.Flatten())\n",
        "#     model.add(keras.layers.Dense(trial.suggest_int('units', 64, 256), activation='relu'))\n",
        "#     model.add(keras.layers.Dropout(trial.suggest_float('dropout', 0.1, 0.5)))\n",
        "#     model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "#     return model\n",
        "\n",
        "# def objective(trial):\n",
        "#     model = create_model(trial)\n",
        "    \n",
        "#     # 定義優化器\n",
        "#     optimizer = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])\n",
        "    \n",
        "#     # 定義影像擴增\n",
        "#     data_augmentation = trial.suggest_categorical('data_augmentation', [False, True])\n",
        "    \n",
        "#     # 編譯模型\n",
        "#     model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "#     if data_augmentation:\n",
        "#         # 影像擴增\n",
        "#         datagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "#         datagen.fit(x_train)\n",
        "#         history = model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=10, validation_data=(x_val, y_val), verbose=0)\n",
        "#     else:\n",
        "#         history = model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val), verbose=0)\n",
        "    \n",
        "#     # 計算驗證集的準確度\n",
        "#     val_accuracy = history.history['val_accuracy'][-1]\n",
        "    \n",
        "#     return val_accuracy\n",
        "\n",
        "# # 創建Optuna Study物件\n",
        "# study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# # 最大試驗次數\n",
        "# n_trials = 50\n",
        "\n",
        "# # 開始進行參數調整\n",
        "# study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "# # 印出最佳參數組合\n",
        "# print('Best Parameters: ')\n",
        "# best_params = study.best_params\n",
        "# for key, value in best_params.items():\n",
        "#     print(f'{key}: {value}')"
      ],
      "metadata": {
        "id": "bR5SmdH_gsta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 經過調參"
      ],
      "metadata": {
        "id": "PXI2_TtuyEkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 更換成調參結果，建立模型\n",
        "model = create_model(drop_rate=0.3, activation=tf.keras.layers.LeakyReLU(alpha=0.01))\n",
        "# 模型總表\n",
        "print(model.summary())\n",
        "\n",
        "# validation_data：使用固定的驗證資料集\n",
        "# validation_split：使用訓練資料的一部分作為驗證資料集\n",
        "history = model.fit(x_img_train_normalize, y_label_train_OneHot, validation_data=(x_img_test_normalize, y_label_test_OneHot), epochs=10, batch_size=64, verbose=1)\n",
        "\n",
        "# 顯示準確率 / 損失率\n",
        "show_history(history,'accuracy','val_accuracy', 'loss', 'val_loss')"
      ],
      "metadata": {
        "id": "Sjiy6OMfyCLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph (繪製神經網路圖)"
      ],
      "metadata": {
        "id": "2jGaXD1m6LG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pydotplus\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "-0LIlMcd0zNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ann_visualizer"
      ],
      "metadata": {
        "id": "P79FFzvYwitA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ann_visualizer.visualize import ann_viz\n",
        "# 可能要等幾秒才會跑出來(顯示在colab files中)\n",
        "ann_viz(model, filename='network.gv', title='Network')"
      ],
      "metadata": {
        "id": "S7NBW8JIhpEI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}